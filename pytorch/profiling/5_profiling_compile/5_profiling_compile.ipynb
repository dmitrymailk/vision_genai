{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3063d14",
   "metadata": {},
   "source": [
    "- https://docs.pytorch.org/docs/stable/torch.compiler_profiling_torch_compile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01a85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "torch.profiler._utils._init_for_cuda_graphs()\n",
    "\n",
    "device = \"cuda\"  # or 'cpu', 'xpu', etc.\n",
    "model = resnet18().to(device)\n",
    "\n",
    "inputs = [torch.randn((5, 3, 224, 224), device=device) for _ in range(10)]\n",
    "\n",
    "model_c = torch.compile(model)\n",
    "\n",
    "\n",
    "def fwd_bwd(inp):\n",
    "    out = model_c(inp)\n",
    "    out.sum().backward()\n",
    "\n",
    "\n",
    "# warm up\n",
    "fwd_bwd(inputs[0])\n",
    "\n",
    "with torch.profiler.profile() as prof:\n",
    "    for i in range(1, 4):\n",
    "        fwd_bwd(inputs[i])\n",
    "        prof.step()\n",
    "\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587d08a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# user can switch between cuda and xpu\n",
    "device = \"cuda\"\n",
    "model = resnet18().to(device)\n",
    "inputs = [torch.randn((5, 3, 224, 224), device=device) for _ in range(10)]\n",
    "\n",
    "model_c = torch.compile(model)\n",
    "\n",
    "\n",
    "def fwd_bwd(inp):\n",
    "    out = model_c(inp)\n",
    "    out.sum().backward()\n",
    "\n",
    "\n",
    "def warmup_compile():\n",
    "    def fn(x):\n",
    "        return x.sin().relu()\n",
    "\n",
    "    x = torch.rand((2, 2), device=device, requires_grad=True)\n",
    "    fn_c = torch.compile(fn)\n",
    "    out = fn_c(x)\n",
    "    out.sum().backward()\n",
    "\n",
    "\n",
    "with torch.profiler.profile() as prof:\n",
    "    with torch.profiler.record_function(\"warmup compile\"):\n",
    "        warmup_compile()\n",
    "\n",
    "    with torch.profiler.record_function(\"resnet18 compile\"):\n",
    "        fwd_bwd(inputs[0])\n",
    "\n",
    "prof.export_chrome_trace(\"trace_compile.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66883e4d",
   "metadata": {},
   "source": [
    "Although there are logging tools for identifying graph breaks, the profiler provides a quick visual method of identifying graph breaks. There are two profiler events to look for: Torch-Compiled Region and CompiledFunction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd42a3",
   "metadata": {},
   "source": [
    "### example of break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58200ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:236: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch._dynamo\n",
    "\n",
    "# user can switch between cuda and xpu\n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "class ModelWithBreaks(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        def create_sequential():\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.Linear(128, 128),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(128, 128),\n",
    "                torch.nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        self.mod1 = create_sequential()\n",
    "        self.mod2 = create_sequential()\n",
    "        self.mod3 = create_sequential()\n",
    "        self.mod4 = create_sequential()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        mod1 = self.mod1(inp)\n",
    "        torch._dynamo.graph_break()\n",
    "        mod2 = self.mod2(mod1)\n",
    "        torch._dynamo.graph_break()\n",
    "        mod3 = self.mod3(mod2)\n",
    "        torch._dynamo.graph_break()\n",
    "        mod4 = self.mod4(mod3)\n",
    "        return mod4\n",
    "\n",
    "\n",
    "model = ModelWithBreaks().to(device)\n",
    "inputs = [torch.randn((128, 128), device=device) for _ in range(10)]\n",
    "\n",
    "model_c = torch.compile(model)\n",
    "\n",
    "\n",
    "def fwd_bwd(inp):\n",
    "    out = model_c(inp)\n",
    "    out.sum().backward()\n",
    "\n",
    "\n",
    "# warm up\n",
    "fwd_bwd(inputs[0])\n",
    "\n",
    "with torch.profiler.profile() as prof:\n",
    "    for i in range(1, 4):\n",
    "        fwd_bwd(inputs[i])\n",
    "        prof.step()\n",
    "\n",
    "prof.export_chrome_trace(\"trace_break.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e0ad5c",
   "metadata": {},
   "source": [
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d14726",
   "metadata": {},
   "source": [
    "### Launch overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3033a868",
   "metadata": {},
   "source": [
    "![alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f884abc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
