{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f7b24bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import ProjectConfiguration\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from diffusers.optimization import get_scheduler\n",
    "from diffusers.training_utils import EMAModel\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import wandb\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from typing import Any, Dict, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from diffusers.configuration_utils import ConfigMixin, register_to_config\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "from diffusers.schedulers.scheduling_utils import (\n",
    "    KarrasDiffusionSchedulers,\n",
    "    SchedulerMixin,\n",
    ")\n",
    "from diffusers.pipelines.pipeline_utils import DiffusionPipeline, ImagePipelineOutput\n",
    "\n",
    "from diffusers.configuration_utils import ConfigMixin, register_to_config\n",
    "\n",
    "\n",
    "from diffusers.models.modeling_utils import ModelMixin\n",
    "\n",
    "# from diffusers.models.unets.unet_2d_blocks import get_down_block, get_up_block\n",
    "from diffusers.models.unets.unet_2d import UNet2DOutput\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMSchedulerOutput\n",
    "from diffusers.utils.torch_utils import is_torch_version\n",
    "\n",
    "\n",
    "from diffusers.models.activations import get_activation\n",
    "\n",
    "from diffusers.utils import deprecate\n",
    "from functools import partial\n",
    "import numbers\n",
    "\n",
    "from diffusers.utils import deprecate, logging\n",
    "from diffusers.utils.torch_utils import is_torch_version, maybe_allow_in_graph\n",
    "from diffusers.models.attention_processor import (\n",
    "    AttnAddedKVProcessor,\n",
    "    SlicedAttnAddedKVProcessor,\n",
    "    SlicedAttnProcessor,\n",
    "    AttentionProcessor,\n",
    ")\n",
    "import inspect\n",
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "from diffusers.utils.torch_utils import apply_freeu\n",
    "from diffusers.configuration_utils import register_to_config\n",
    "from diffusers.utils import deprecate, logging\n",
    "\n",
    "\n",
    "from diffusers.models.normalization import (\n",
    "    RMSNorm,\n",
    ")\n",
    "\n",
    "\n",
    "class ResnetBlock2D(nn.Module):\n",
    "    r\"\"\"ok\n",
    "    A Resnet block.\n",
    "\n",
    "    Parameters:\n",
    "        in_channels (`int`): The number of channels in the input.\n",
    "        out_channels (`int`, *optional*, default to be `None`):\n",
    "            The number of output channels for the first conv2d layer. If None, same as `in_channels`.\n",
    "        dropout (`float`, *optional*, defaults to `0.0`): The dropout probability to use.\n",
    "        temb_channels (`int`, *optional*, default to `512`): the number of channels in timestep embedding.\n",
    "        groups (`int`, *optional*, default to `32`): The number of groups to use for the first normalization layer.\n",
    "        groups_out (`int`, *optional*, default to None):\n",
    "            The number of groups to use for the second normalization layer. if set to None, same as `groups`.\n",
    "        eps (`float`, *optional*, defaults to `1e-6`): The epsilon to use for the normalization.\n",
    "        non_linearity (`str`, *optional*, default to `\"swish\"`): the activation function to use.\n",
    "        time_embedding_norm (`str`, *optional*, default to `\"default\"` ): Time scale shift config.\n",
    "            By default, apply timestep embedding conditioning with a simple shift mechanism. Choose \"scale_shift\" for a\n",
    "            stronger conditioning with scale and shift.\n",
    "        kernel (`torch.Tensor`, optional, default to None): FIR filter, see\n",
    "            [`~models.resnet.FirUpsample2D`] and [`~models.resnet.FirDownsample2D`].\n",
    "        output_scale_factor (`float`, *optional*, default to be `1.0`): the scale factor to use for the output.\n",
    "        use_in_shortcut (`bool`, *optional*, default to `True`):\n",
    "            If `True`, add a 1x1 nn.conv2d layer for skip-connection.\n",
    "        up (`bool`, *optional*, default to `False`): If `True`, add an upsample layer.\n",
    "        down (`bool`, *optional*, default to `False`): If `True`, add a downsample layer.\n",
    "        conv_shortcut_bias (`bool`, *optional*, default to `True`):  If `True`, adds a learnable bias to the\n",
    "            `conv_shortcut` output.\n",
    "        conv_2d_out_channels (`int`, *optional*, default to `None`): the number of channels in the output.\n",
    "            If None, same as `out_channels`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        in_channels: int,\n",
    "        out_channels: Optional[int] = None,\n",
    "        conv_shortcut: bool = False,\n",
    "        dropout: float = 0.0,\n",
    "        temb_channels: int = 512,\n",
    "        groups: int = 32,\n",
    "        groups_out: Optional[int] = None,\n",
    "        pre_norm: bool = True,\n",
    "        eps: float = 1e-6,\n",
    "        non_linearity: str = \"swish\",\n",
    "        skip_time_act: bool = False,\n",
    "        time_embedding_norm: str = \"default\",  # default, scale_shift,\n",
    "        kernel: Optional[torch.Tensor] = None,\n",
    "        output_scale_factor: float = 1.0,\n",
    "        use_in_shortcut: Optional[bool] = None,\n",
    "        up: bool = False,\n",
    "        down: bool = False,\n",
    "        conv_shortcut_bias: bool = True,\n",
    "        conv_2d_out_channels: Optional[int] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pre_norm = True\n",
    "        self.in_channels = in_channels\n",
    "        out_channels = in_channels if out_channels is None else out_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.use_conv_shortcut = conv_shortcut\n",
    "        # self.up=False\n",
    "        # self.down=False\n",
    "        self.up = up\n",
    "        self.down = down\n",
    "        self.output_scale_factor = output_scale_factor\n",
    "        self.time_embedding_norm = time_embedding_norm\n",
    "        self.skip_time_act = skip_time_act\n",
    "\n",
    "        if groups_out is None:\n",
    "            groups_out = groups\n",
    "\n",
    "        self.norm1 = torch.nn.GroupNorm(\n",
    "            num_groups=groups, num_channels=in_channels, eps=eps, affine=True\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "\n",
    "        self.time_emb_proj = nn.Linear(temb_channels, out_channels)\n",
    "\n",
    "        self.norm2 = torch.nn.GroupNorm(\n",
    "            num_groups=groups_out, num_channels=out_channels, eps=eps, affine=True\n",
    "        )\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        conv_2d_out_channels = conv_2d_out_channels or out_channels\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, conv_2d_out_channels, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        # self.nonlinearity=SiLU()\n",
    "        self.nonlinearity = get_activation(non_linearity)\n",
    "\n",
    "        self.upsample = self.downsample = None\n",
    "        # self.use_in_shortcut=False\n",
    "        self.use_in_shortcut = (\n",
    "            self.in_channels != conv_2d_out_channels\n",
    "            if use_in_shortcut is None\n",
    "            else use_in_shortcut\n",
    "        )\n",
    "\n",
    "        self.conv_shortcut = None\n",
    "        if self.use_in_shortcut:\n",
    "            self.conv_shortcut = nn.Conv2d(\n",
    "                in_channels,\n",
    "                conv_2d_out_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=conv_shortcut_bias,\n",
    "            )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_tensor: torch.Tensor,\n",
    "        temb: torch.Tensor,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ) -> torch.Tensor:\n",
    "        if len(args) > 0 or kwargs.get(\"scale\", None) is not None:\n",
    "            deprecation_message = \"The `scale` argument is deprecated and will be ignored. Please remove it, as passing it will raise an error in the future. `scale` should directly be passed while calling the underlying pipeline component i.e., via `cross_attention_kwargs`.\"\n",
    "            deprecate(\"scale\", \"1.0.0\", deprecation_message)\n",
    "        hidden_states = input_tensor\n",
    "\n",
    "        # torch.Size([16, 128, 64, 64])\n",
    "        hidden_states = self.norm1(hidden_states)\n",
    "        # torch.Size([16, 128, 64, 64])\n",
    "        hidden_states = self.nonlinearity(hidden_states)\n",
    "        # torch.Size([16, 128, 64, 64])\n",
    "        hidden_states = self.conv1(hidden_states)\n",
    "\n",
    "        if self.time_emb_proj is not None:\n",
    "            if not self.skip_time_act:\n",
    "                temb = self.nonlinearity(temb)\n",
    "            temb = self.time_emb_proj(temb)[:, :, None, None]\n",
    "        # self.time_embedding_norm=\"default\"\n",
    "\n",
    "        # temb=torch.Size([16, 128, 1, 1])\n",
    "        if temb is not None:\n",
    "            hidden_states = hidden_states + temb\n",
    "        hidden_states = self.norm2(hidden_states)\n",
    "\n",
    "        hidden_states = self.nonlinearity(hidden_states)\n",
    "\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        # torch.Size([16, 128, 64, 64])\n",
    "        hidden_states = self.conv2(hidden_states)\n",
    "\n",
    "        if self.conv_shortcut is not None:\n",
    "            input_tensor = self.conv_shortcut(input_tensor.contiguous())\n",
    "        # input_tensor=torch.Size([4, 128, 64, 64])\n",
    "        # hidden_states=torch.Size([4, 128, 64, 64])\n",
    "        # self.output_scale_factor=1.0\n",
    "        output_tensor = (input_tensor + hidden_states) / self.output_scale_factor\n",
    "\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22bed9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_tensor = torch.randn(\n",
    "    (16, 128, 64, 64),\n",
    "    device=\"cuda\",\n",
    ")\n",
    "temb_local = torch.randn(\n",
    "    (16, 512),\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "143ae373",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_resnet = ResnetBlock2D(\n",
    "    in_channels=128,\n",
    "    out_channels=128,\n",
    "    temb_channels=512,\n",
    "    eps=1e-05,\n",
    "    groups=128,\n",
    "    dropout=0.0,\n",
    "    time_embedding_norm=\"default\",\n",
    "    non_linearity=\"silu\",\n",
    "    output_scale_factor=1.0,\n",
    "    pre_norm=True,\n",
    ")\n",
    "default_resnet = default_resnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15cc2ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_resnet.skip_time_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4183810e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration s 1000,  0.9223389625549316\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "amount = 1000\n",
    "start = time.time()\n",
    "for _ in range(amount):\n",
    "    result = default_resnet(\n",
    "        temp_tensor,\n",
    "        temb_local,\n",
    "    )\n",
    "duration = time.time() - start\n",
    "print(\"duration s 1000, \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ec4820",
   "metadata": {},
   "source": [
    "### torch compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f89011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_resnet = ResnetBlock2D(\n",
    "    in_channels=128,\n",
    "    out_channels=128,\n",
    "    temb_channels=512,\n",
    "    eps=1e-05,\n",
    "    groups=128,\n",
    "    dropout=0.0,\n",
    "    time_embedding_norm=\"default\",\n",
    "    non_linearity=\"silu\",\n",
    "    output_scale_factor=1.0,\n",
    "    pre_norm=True,\n",
    ")\n",
    "compile_resnet = compile_resnet.cuda()\n",
    "compile_resnet = torch.compile(\n",
    "    compile_resnet,\n",
    "    fullgraph=True,\n",
    "    mode=\"reduce-overhead\",\n",
    "    # mode=\"max-autotune\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9270f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_resnet = compile_resnet.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86f4c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration s 1000,  0.4762232303619385\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "amount = 1000\n",
    "start = time.time()\n",
    "for _ in range(amount):\n",
    "    compile_resnet(\n",
    "        temp_tensor,\n",
    "        temb_local,\n",
    "    )\n",
    "duration = time.time() - start\n",
    "print(\"duration s 1000, \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278030af",
   "metadata": {},
   "source": [
    "### Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5984949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/_inductor/cudagraph_trees.py:2442: UserWarning: Unable to hit fast path of CUDAGraphs because of pending, uninvoked backwards. Consider running with torch.no_grad() or using torch.compiler.cudagraph_mark_step_begin() before each model invocation\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA]\n",
    "device = \"cuda\"\n",
    "sort_by_keyword = device + \"_time_total\"\n",
    "\n",
    "compile_resnet = ResnetBlock2D(\n",
    "    in_channels=128,\n",
    "    out_channels=128,\n",
    "    temb_channels=512,\n",
    "    eps=1e-05,\n",
    "    groups=128,\n",
    "    dropout=0.0,\n",
    "    time_embedding_norm=\"default\",\n",
    "    non_linearity=\"silu\",\n",
    "    output_scale_factor=1.0,\n",
    "    pre_norm=True,\n",
    ")\n",
    "\n",
    "compile_resnet = compile_resnet.cuda()\n",
    "compile_resnet = torch.compile(\n",
    "    compile_resnet,\n",
    "    fullgraph=True,\n",
    "    mode=\"reduce-overhead\",\n",
    ")\n",
    "amount = 10\n",
    "\n",
    "with profile(\n",
    "    activities=activities,\n",
    "    record_shapes=True,\n",
    ") as prof:\n",
    "    for _ in range(amount):\n",
    "        result = compile_resnet(\n",
    "            temp_tensor,\n",
    "            temb_local,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d307ade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Torch-Compiled Region: 0/1         0.03%     456.878us        99.98%        1.352s     135.241ms       0.000us         0.00%       9.882ms     988.188us            10  \n",
      "                                       CompiledFunction         0.53%       7.136ms        99.94%        1.352s     135.195ms       9.125ms        92.34%       9.882ms     988.188us            10  \n",
      "                    CUDAGraphNode.replay (dynamo_timed)         0.00%       0.000us         0.00%       0.000us       0.000us       9.105ms        92.14%       9.105ms     910.481us            10  \n",
      "void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s168...         0.00%       0.000us         0.00%       0.000us       0.000us       5.060ms        51.21%       5.060ms     253.007us            20  \n",
      "                   triton_red_fused_native_group_norm_5         0.00%       0.000us         0.00%       0.000us       0.000us       1.095ms        11.08%       1.095ms     109.528us            10  \n",
      "void cudnn::engines_precompiled::convertTensor_kerne...         0.00%       0.000us         0.00%       0.000us       0.000us       1.053ms        10.66%       1.053ms      26.325us            40  \n",
      "    CUDAGraphTreeManager.record_function (dynamo_timed)         0.49%       6.624ms        99.41%        1.345s     134.482ms       0.000us         0.00%     757.290us      75.729us            10  \n",
      "                 triton_poi_fused_add_convolution_div_7         0.00%       0.000us         0.00%       0.000us       0.000us     743.850us         7.53%     743.850us      74.385us            10  \n",
      "                                   aten::_foreach_copy_         0.01%     100.362us         0.02%     210.861us      21.086us     736.714us         7.46%     736.714us      73.671us            10  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     736.714us         7.46%     736.714us      73.671us            10  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.353s\n",
      "Self CUDA time total: 9.882ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=sort_by_keyword, row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c156298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof.export_chrome_trace(\"trace_default_reduce-overhead.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
